<!DOCTYPE html>
<html lang="en-US">
<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">


<meta http-equiv="cache-control" content="no-cache, must-revalidate, post-check=0, pre-check=0" />
<meta http-equiv="cache-control" content="max-age=0" />
<meta http-equiv="expires" content="0" />
<meta http-equiv="expires" content="Tue, 01 Jan 1980 1:00:00 GMT" />
<meta http-equiv="pragma" content="no-cache" />  

<meta name="description" content="Image Matching: Local Features &amp; Beyond - CVPR 2025 Workshop">
<meta name="keywords" content="image,matching,local Features, CVPR 2025, Workshop, CVPR">

<base href="https://image-matching-workshop.github.io/">

<title>Seventh Workshop on Image Matching: Local Features &amp; Beyond</title>

<meta name="generator" content="Hugo 0.131.0">



<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,400|Roboto+Slab:400,700|Roboto:300,300i,400,400i,500,500i,700,700i">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css">
<link rel="stylesheet" href="https://image-matching-workshop.github.io/css/datatables.min.css">
<link rel="stylesheet" href="https://image-matching-workshop.github.io/css/balloon.min.css">
<link rel="stylesheet" href="https://image-matching-workshop.github.io/css/main.css">
<link rel="stylesheet" href="https://image-matching-workshop.github.io/css/custom.css">




<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="theme-color" content="#ffffff">





<script src="https://www.gstatic.com/charts/loader.js"></script>
<script type="text/javascript" src="https://image-matching-workshop.github.io/js/jquery.latest.min.js"></script>
<script type="text/javascript" src="https://image-matching-workshop.github.io/js/jquery.csv.min.js"></script>
<script type="text/javascript" src="https://image-matching-workshop.github.io/js/datatables.min.js"></script>
<script type="text/javascript" src="https://image-matching-workshop.github.io/js/three.js"></script>
<script type="text/javascript" src="https://image-matching-workshop.github.io/js/PCDLoader.js"></script>
<script type="text/javascript" src="https://image-matching-workshop.github.io/js/TrackballControls.js"></script>
<script type="text/javascript" src="https://image-matching-workshop.github.io/js/WebGL.js"></script>
<script type="text/javascript" src="https://image-matching-workshop.github.io/js/stats.min.js"></script>
<script>
$(document).ready(function (){
    var table = $('.leaderboard_stereo').DataTable({
        "columnDefs": [{targets:[0, 2], orderSequence: ['desc', 'asc']}],
        "columnDefs": [{targets:[1, 3, 4, 5, 6, 7, 8, 9], orderSequence: ['desc', 'asc']}],
        "order": [[7, 'desc']],
        responsive: {
            details: {
                renderer: function ( api, rowIdx, columns ) {
                    var data = $.map( columns, function ( col, i ) {
                        return col.hidden ?
                            '<tr data-dt-row="'+col.rowIndex+'" data-dt-column="'+col.columnIndex+'">'+
                                '<td class="align_left details_title"><b>'+col.title+':'+'</b></td> '+
                                '<td class="align_left details_data">'+col.data+'</td>'+
                            '</tr>' :
                            '';
                    } ).join('');
 
                    return data ?
                        $('<table/>').append( data ) :
                        false;
                }
            }
        }
    });

    var table = $('.leaderboard_mvs').DataTable({
        "columnDefs": [{targets:[0, 2], orderSequence: ['desc', 'asc']}],
        "columnDefs": [{targets:[1, 3, 4, 5, 6, 7, 8, 9, 10, 11], orderSequence: ['desc', 'asc']}],
        "order": [[9, 'desc']],
        responsive: {
            details: {
                renderer: function ( api, rowIdx, columns ) {
                    var data = $.map( columns, function ( col, i ) {
                        return col.hidden ?
                            '<tr data-dt-row="'+col.rowIndex+'" data-dt-column="'+col.columnIndex+'">'+
                                '<td class="align_left details_title"><b>'+col.title+':'+'</b></td> '+
                                '<td class="align_left details_data">'+col.data+'</td>'+
                            '</tr>' :
                            '';
                    } ).join('');
 
                    return data ?
                        $('<table/>').append( data ) :
                        false;
                }
            }
        }
    });

    var table = $('.checkerboard').DataTable({
        "columnDefs": [{targets:[0], orderSequence: ['desc', 'asc']}],
        "columnDefs": [{targets:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], orderSequence: ['desc', 'asc']}],
        "order": [[12, 'desc']],
        responsive: {
            details: {
                renderer: function ( api, rowIdx, columns ) {
                    var data = $.map( columns, function ( col, i ) {
                        return col.hidden ?
                            '<tr data-dt-row="'+col.rowIndex+'" data-dt-column="'+col.columnIndex+'">'+
                                '<td class="align_left details_title"><b>'+col.title+':'+'</b></td> '+
                                '<td class="align_left details_data">'+col.data+'</td>'+
                            '</tr>' :
                            '';
                    } ).join('');
 
                    return data ?
                        $('<table/>').append( data ) :
                        false;
                }
            }
        }
    });

    $('.tablelist').dataTable({searching: false, paging: false, info: false});

    

    
    $('#btn-show-all-children').on('click', function(){
        
        table.rows(':not(.parent)').nodes().to$().find('td:first-child').trigger('click');
    });

    
    $('#btn-hide-all-children').on('click', function(){
        
        table.rows('.parent').nodes().to$().find('td:first-child').trigger('click');
    });
});
</script>
</head>
<body lang="en-US">
<div class="container">


<header class="row text-left title">
  <h1 class="title"></h1>
</header>
<section id="category-pane" class="row meta">
  
  <div class="col-md-12">
    <h6 class="text-left meta">
        PUBLISHED ON OCT 2, 2016 
      
    </h6>
  </div>
  
</section>
<section id="content-pane" class="row">
  <div class="col-md-12 text-justify content">
    <h2 id="schedule">Schedule</h2>
<ul>
<li>13:00-13:15	Welcome session</li>
</ul>
<p><em>INVITED TALKS</em></p>
<ul>
<li>13:15-14:00	SuperPoint and SuperGlue: Lessons Learned (Tomasz Malisiewicz, Meta) ZOOM (<a href=slides/2022/tom.pdf>slides</a>)</li>
<li>14:00-14:45	Large-scale 3D reconstruction Deployment - Successes, Challenges, Open Problems (Aleš Hrabalík, Capturing Reality/Epic Games) LIVE</li>
</ul>
<p><em>BREAK</em></p>
<ul>
<li>14:45-15:00	First coffee break + poster session</li>
</ul>
<p><em>WORKSHOP PAPER TALKS</em></p>
<ul>
<li>15:00-15:10	Unstructured Object Matching using Co-Salient Region Segmentation (Alin-Ionut Popa, Amazon) LIVE</li>
<li>15:10-15:20	Nerfels: Renderable Neural Codes for Improved Camera Pose Estimation (Daniel DeTone, Meta) LIVE</li>
<li>15:20-15:30	Feature Query Networks: Neural Surface Description for Camera Pose Refinement (Hugo Germain, Ecole des Ponts ParisTech) LIVE (<a href="https://youtu.be/lTw1RntC2qc">video</a>)</li>
<li>15:30-15:40	Learning Co-segmentation by Segment Swapping for Retrieval and Discovery (Xi Shen, École des Ponts ParisTech) ZOOM (<a href="https://youtu.be/9pKwNGZPDr8">video</a>)</li>
<li>15:40-15:50	DA-AE: Disparity-Alleviation Auto-Encoder Towards Categorization of Heritage Images for Aggrandized 3D Reconstruction (Dikshit Hegde, KLE Tech. Univ.) ZOOM (<a href="https://youtu.be/OF6pEk6fNBE">video</a>)</li>
<li>15:50-16:00	Detecting and Suppressing Marine Snow for Underwater Visual SLAM (Lars Martin Hodne &amp; Eirik Leikvoll, NTNU) LIVE</li>
<li>16:00-16:10	A case for using rotation invariant features in state of the art feature matchers (Georg Bökman, Chalmers) LIVE (<a href="https://youtu.be/-s3_2eebDzk">video</a>)</li>
</ul>
<p><em>BREAK</em></p>
<ul>
<li>16:10-16:25	Second coffee break + poster session</li>
</ul>
<p><em>CHALLENGE TALKS</em></p>
<ul>
<li>16:25-16:35	Challenge intro</li>
<li>16:35-16:45	1st place: Shuai Wu (-), Yuki Kashiwaba (Iterra Solutions Inc), Hongjian Song (South China University of Technology) Canming Wang (-) ZOOM</li>
<li>16:45-16:55	3rd place: Jian Xu, Kai Huang, Wen Sun, Gaotong Yu, Zhicheng Wang, Kejian Wu (NReal.ai) ZOOM (video - upload soon)</li>
<li>16:55-17:05	5th place: Dongli Tan, Jiangjiang Liu, Xingyu Chen, Qi Zhang, Tong Wu, Ruixin Zhang, Chao Chen, Yunhang Shen, Chunhua Shen, Rongrong Ji (Youtu Lab, Xiamen University, Nankai University) ZOOM (video - upload soon)</li>
<li>17:05-17:15	7th place: Hyeokjoon Kwon, Seungho Back (Nearthlab) LIVE</li>
<li><del>17:15-17:25	2nd place: Hongkai Chen (HKUST) ZOOM</del> Declined</li>
<li>17:25-17:XX	Discussion &amp; wrap-up</li>
</ul>
<h2 id="about">About</h2>
<p>The Fourth Workshop on Image Matching: Local Features and Beyond will be held at <a href="http://cvpr2022.thecvf.com/">CVPR 2022</a> on June 20, 2022 (afternoon, Central Standard Time, USA). The workshop will once again feature an <em>open challenge</em> which will be announced in the following weeks. Further details will be announced before the conference.</p>
<p>Traditional, keypoint-based formulations for image matching are still
very competitive on tasks such as Structure from Motion (SfM), despite
recent efforts on tackling pose estimation with dense networks.  In
practice, many state-of-the-art pipelines still rely on methods that
stood the test of time, such as SIFT or RANSAC.</p>
<p>In this workshop, we aim to encourage novel strategies for image
matching that deviate from and advance traditional formulations, with
a focus on large-scale, wide-baseline matching for 3D reconstruction
or pose estimation.  This can be achieved by applying new technologies
to sparse feature matching, or doing away with keypoints and
descriptors entirely.</p>
<p>Topics include (but are not limited to):</p>
<ul>
<li>Formulations of keypoint extraction and matching pipelines with deep networks.</li>
<li>Application of geometric constraints into the training of deep networks.</li>
<li>Leveraging additional cues such as semantics and mono-depth estimates.</li>
<li>Methods addressing adversarial conditions where current methods fail (weather changes, day versus night, etc.).</li>
<li>Attention mechanisms to match salient image regions.</li>
<li>Integration of differentiable components into 3D reconstruction frameworks.</li>
<li>Connecting local descriptors/image matching with global descriptors/image retrieval.</li>
<li>Matching across different data modalities such as aerial versus ground.</li>
<li>Large-scale evaluation of classical and modern methods for image matching, by means of our open challenge.</li>
<li>New perception devices such as event-based cameras.</li>
<li>Other topics related to image matching, structure from motion, mapping, and re-localization, such as privacy-preserving representations.</li>
</ul>
<p>The last two editions were livestreamed on YouTube and remain available: <a href="https://youtu.be/UQ4uJX7UDB8">2020</a>, <a href="https://youtu.be/9cVV9m_b5Ys">2021</a>.</p>
<h2 id="organisers">Organisers</h2>
<a href="http://vbalnt.github.io/">
<div class="item">
    <img class="headshot" src="img/vassileios.jpg"/>
    <span class="name">Vassileios <br>Balntas</span>
    <span class="affiliation">Meta</span>
</div>
</a>
<a href="https://www.labri.fr/perso/vlepetit/">
<div class="item">
    <img class="headshot" src="img/vincent.jpg"/>
    <span class="name">Vincent <br>Lepetit</span>
    <span class="affiliation">ENPC ParisTech</span>
</div>
</a>
<a href="http://cmp.felk.cvut.cz/~matas/">
<div class="item">
    <img class="headshot" src="img/jiri.jpg"/>
    <span class="name"> Jiri <br>Matas</span>
    <span class="affiliation">Czech Technical University</span>
</div>
</a>
<a href="http://cmp.felk.cvut.cz/~mishkdmy/">
<div class="item">
    <img class="headshot" src="img/dmytro.jpg"/>
    <span class="name">Dmytro <br>Mishkin</span>
    <span class="affiliation">Czech Technical University</span>
</div>
</a>
<a href="https://demuc.de/">
<div class="item">
    <img class="headshot" src="img/johannes.jpeg"/>
    <span class="name">Johannes <br> Schönberger</span>
    <span class="affiliation">Microsoft</span>
</div>
</a>
<a href="http://icwww.epfl.ch/~trulls/">
<div class="item">
    <img class="headshot" src="img/eduard.png"/>
    <span class="name">Eduard <br> Trulls</span>
    <span class="affiliation">Google</span>
</div>
</a>
<a href="https://www.cs.ubc.ca/~kmyi/">
<div class="item">
    <img class="headshot" src="img/kwang.jpeg"/>
    <span class="name">Kwang Moo <br>Yi</span>
    <span class="affiliation">University of British Columbia</span>
</div>
</a>
<br />
<h2 id="invited-speakers">Invited speakers</h2>
<ul>
<li><a href="https://tom.ai/">Tomasz Malisiewicz</a>, Meta (confirmed)</li>
<li><a href="https://www.capturingreality.com/">Ales Hrabalik</a>, CapturingReality (confirmed)</li>
</ul>
<h2 id="accepted-papers">Accepted papers</h2>
<ul>
<li><a href="pdf/2022/1.pdf">Unstructured Object Matching using Co-Salient Region Segmentation</a>, by Ioana-Sabina Stoian (Amazon), Ionut C Sandu (Amazon), Daniel Voinea (Amazon), Alin-Ionut Popa (Amazon).</li>
<li><a href="pdf/2022/2.pdf">Nerfels: Renderable Neural Codes for Improved Camera Pose Estimation</a>, by Gil Avraham (Monash University), Julian Straub (Facebook Reality Labs), Tianwei Shen (Facebook), Tsun-Yi Yang (Facebook), Hugo Germain (Ecole des Ponts ParisTech), Chris Sweeney (Facebook Reality Labs), Vasileios Balntas (Facebook Reality Labs), David Novotny (Facebook AI Research), Daniel DeTone (Facebook), Richard Newcombe (Facebook)</li>
<li><a href="pdf/2022/3.pdf">Feature Query Networks: Neural Surface Description for Camera Pose Refinement</a>, by Hugo Germain (Ecole des Ponts ParisTech)x, Daniel DeTone (Facebook), Geoffrey M Pascoe (Facebook), Tanner Schmidt (Facebook Reality Labs), David Novotny (Facebook AI Research), Richard Newcombe (Facebook), Chris Sweeney (Facebook Reality Labs), Richard Szeliski (The University of Washington), Vasileios Balntas (Facebook Reality Labs)</li>
<li><a href="pdf/2022/4.pdf">Learning Co-segmentation by Segment Swapping for Retrieval and Discovery</a>, by Xi Shen (École des Ponts ParisTech), Alexei A Efros (UC Berkeley), Armand Joulin (Facebook AI Research), Mathieu Aubry (École des ponts ParisTech)</li>
<li><a href="pdf/2022/6.pdf">DA-AE: Disparity-Alleviation Auto-Encoder Towards Categorization of Heritage Images for Aggrandized 3D Reconstruction</a>, by Dikshit Hegde (KLE Technological University), Tejas Anvekar (KLE Technological University), Ramesh Tabib (KLE Technological University), Uma Mudenagudi (KLE Technological University)</li>
<li><a href="pdf/2022/7.pdf">Detecting and Suppressing Marine Snow for Underwater Visual SLAM</a>, by Lars Martin Hodne (Norwegian University of Science and Technology), Eirik Leikvoll (Norwegian University of Science and Technology), Mauhing Yip (Norwegian University of Science and Technology), Andreas L Teigen (Norwegian University of Science and Technology), Annette Stahl (Norwegian University of Science and Technology), Rudolf Mester (Norwegian University of Science and Technology)</li>
<li><a href="pdf/2022/12.pdf">A case for using rotation invariant features in state of the art feature matchers</a>, by Georg Bökman (Chalmers University of Technology), Fredrik Kahl (Chalmers)</li>
</ul>
<h2 id="news">News</h2>
<ul>
<li>April 25, 2022: Announcing accepted papers.</li>
<li>April 5, 2022: Moved the paper decisions date to April 15 to give more time to reviewers. Thanks for your participation!</li>
<li>April 4, 2022: Announcing the <a href="https://www.kaggle.com/competitions/image-matching-challenge-2022/overview">2022 Image Matching Challenge</a>, which has moved to Kaggle! Opening today, and running for two months until June 2.</li>
<li>February 23, 2022: CVPR has extended the camera-ready deadline for workshop papers, so we have pushing the deadline by a few days, from March 28 to April 4.</li>
<li>January 17, 2022: The workshop has been renewed! We are sending out our new call for papers. The 2022 edition of the challenge will be announced in a few weeks.</li>
<li>June 28, 2021: The conference is over! Thanks for your participation, and hope to see you next year. Slides have been uploaded <a href="slides/slides-imw2021.pdf">here</a>.</li>
<li>June 21, 2021: Announcing the <a href="https://www.cs.ubc.ca/research/image-matching-challenge/2021/news/2021-06-21/">IMC challenge winners</a>, and tentative schedule (top of this page). See you this Friday!</li>
<li>March 11, 2021: Announcing our invited speakers: Professors Marc Pollefeys and Davide Scaramuzza.</li>
<li>March 3, 2021: Announcing our call for papers. The challenge will be open in about ~1mo.</li>
<li>January 29, 2021: Updating website to announce the third (2021) edition of the workshop. Details on the workshop, challenge, and call for papers to follow soon.</li>
</ul>
<h2 id="important-dates">Important dates</h2>
<ul>
<li><strong>Paper submission deadline:</strong> April 4, 2022.</li>
<li><strong>Notification to authors:</strong> April 15, 2022.</li>
<li><strong>Camera-ready deadline:</strong> April 19, 2022 (hard deadline on April 20!).</li>
<li><strong>Challenge submission deadline:</strong> TBA (<a href="https://www.cs.ubc.ca/research/image-matching-challenge/">see challenge website</a>)</li>
</ul>
<!--* **Deadline for short descriptions on challenge submissions:** TBA ([see challenge website](https://www.cs.ubc.ca/research/image-matching-challenge/))-->
<ul>
<li><strong>Workshop date:</strong> June 20, 2022, afternoon (exact schedule TBA)</li>
</ul>
<p>(All dates are at 11:59PM, Pacific Time.)</p>
<h2 id="challenge">Challenge</h2>
<ul>
<li><a href="https://github.com/ubc-vision/image-matching-benchmark">Image Matching Benchmark</a></li>
<li><a href="https://www.cs.ubc.ca/research/image-matching-challenge/">Image Matching Challenge</a></li>
</ul>
<!--## Paper Submission-->
<!---->
<!--We welcome full paper submissions and extended abstracts, which will be presented in the workshop as posters. Please refer to the [Call for Papers](/papers).-->
<h2 id="contact">Contact</h2>
<p>Please reach us with any questions at <a href="mailto:image-matching@googlegroups.com">image-matching@googlegroups.com</a>.</p>
<br />
<br />
<br />

  </div>
</section>
<section id="tag-pane" class="row meta">
  
  <div class="col-md-12">
    <h6 class="text-right meta">
      
    </h6>
  </div>
  
</section>








<section id="menu-pane" class="row menu text-center">
  
  
  <span><a class="menu-item" href="https://image-matching-workshop.github.io/cvpr2023/">&lt; prev | </a></span>
  
  
  <span><a class="menu-item" href="/"></a></span>
  
  
  <span><a class="menu-item" href="https://image-matching-workshop.github.io/cvpr2021/"> | next &gt;</a></span>
  
  
  <h4 class="text-center"><a class="menu-item" href="https://image-matching-workshop.github.io/">home</a></h4>
</section>



<footer class="row text-center footer">
  
  
</footer>

</div>




  
    
      
    
  



<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="js/main.js"></script>

</script>
</body>
</html>


